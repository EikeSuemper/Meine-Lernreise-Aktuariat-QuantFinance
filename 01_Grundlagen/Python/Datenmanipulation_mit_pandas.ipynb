{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05ab61c5-6834-4f17-b209-d45e8663328b",
   "metadata": {},
   "source": [
    "# Datenmanipulation mit Pandas in Python\n",
    "\n",
    "## DataFrames einlesen: CSV, Excel, URL und wichtige Parameter\n",
    "\n",
    "Pandas kann fast jedes Datenformat einlesen. Die wichtigsten Funktionen sind:\n",
    "\n",
    "| Funktion           | Typische Quelle                         |\n",
    "|--------------------|-----------------------------------------|\n",
    "| `pd.read_csv()`    | CSV, TSV, Textdateien                   |\n",
    "| `pd.read_excel()`  | .xlsx, .xls                             |\n",
    "| `pd.read_json()`   | JSON, APIs                              |\n",
    "| `pd.read_html()`   | Tabellen aus Webseiten                  |\n",
    "| direkt aus URL     | beinhaltet obige Funktionen, ohne es vorher herunter zu laden |\n",
    "\n",
    "### CSV einlesen: `pd.read_csv()` mit den wichtigsten Parametern\n",
    "\n",
    "Die wichtigsten Parameter der Funktion sind Folgende:\n",
    "\n",
    "| Parameter         | Wirkung                                      | Typisches Problem ohne diesen Parameter      |\n",
    "|-------------------|----------------------------------------------|-----------------------------------------------|\n",
    "| `sep` oder `delimiter` | Trenner in der CSV (oft `;`, `|`, `\\t`)  | Spalten werden falsch getrennt                |\n",
    "| `encoding`        | Zeichenkodierung (`utf-8`, `latin1`, `cp1252`) | Umlaute oder Fehler                       |\n",
    "| `decimal`         | Dezimaltrennzeichen (`,` statt `.`)          | 52.000,50 wird zu String                      |\n",
    "| `thousands`       | Tausendertrennzeichen (`.` oder Leerzeichen) | Zahlen werden als String gelesen              |\n",
    "| `parse_dates`     | Spalten automatisch als Datum parsen         | Datum bleibt String                           |\n",
    "| `dtype`           | Datentypen explizit setzen                   | Pandas rät falsch (z.B. ID als float)         |\n",
    "| `usecols`         | Nur bestimmte Spalten laden                  | Speicher und Zeit sparen                        |\n",
    "| `nrows`           | Nur erste n Zeilen laden                     | Schnell reinschauen                           |\n",
    "\n",
    "\n",
    "#### Beispiel: Deutsche CSV mit Semikolon, Komma als Dezimal und Umlauten einlesen\n",
    "\n",
    "Bevor man mit echten Dateien arbeitet, erstelle ich ein kleines, aber realistisches Beispiel:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = {\n",
    "    'Name': ['Anna', 'Ben', 'Clara', 'David', 'Emma'],\n",
    "    'Alter': [28, 34, 19, 42, 31],\n",
    "    'Gehalt_EUR': ['52.000,50', '68.000,00', '45.000,75', '82.000,00', '59.000,25'],\n",
    "    'Eintritt': ['2021-03-15', '2020-11-01', '2023-07-20', '2019-01-10', '2022-05-05'],\n",
    "    'Abteilung': ['IT', 'Vertrieb', 'IT', 'Vertrieb', 'Marketing']\n",
    "}\n",
    "df_demo = pd.DataFrame(data)\n",
    "df_demo.to_csv('mitarbeiter_demo.csv', index=False, sep=';', decimal=',')\n",
    "df_demo.to_excel('mitarbeiter_demo.xlsx', index=False)\n",
    "\n",
    "print(\"Demo-Dateien erstellt: mitarbeiter_demo.csv und mitarbeiter_demo.xlsx\")\n",
    "```\n",
    "\n",
    "Die Datei enthält typisch deutsche „Problemfälle“:\n",
    "- Gehalt mit Punkt als Tausender- und Komma als Dezimaltrennzeichen ( 52.000,50)\n",
    "- Semikolon als Spaltentrenner\n",
    "- Datum im Format YYYY-MM-DD\n",
    "- Umlaute und Sonderzeichen\n",
    "\n",
    "So kann man alle wichtigen Parameter von `pd.read_csv()` und `pd.read_excel()` direkt testen, ohne dass man erst eine externe Datei herunterladen muss.\n",
    "\n",
    "```python\n",
    "df = pd.read_csv(\n",
    "    'mitarbeiter_demo.csv',\n",
    "    sep=';',                    # Deutscher Standard: Semikolon\n",
    "    encoding='utf-8',           # oder 'latin1' bei alten Excel-Exports\n",
    "    decimal=',',                # 52.000,50: float 52000.50\n",
    "    thousands='.',              # 52.000,50: korrekt erkannt\n",
    "    parse_dates=['Eintritt'],   # Spalte als datetime\n",
    "    dtype={'Name': 'string', 'Abteilung': 'category'},  # Speicher sparen\n",
    "    usecols=['Name', 'Alter', 'Gehalt_EUR', 'Eintritt', 'Abteilung'],  # nur diese Spalten\n",
    "    nrows=None                   # None = alle Zeilen (oder z.B. 100 zum Testen)\n",
    ")\n",
    "\n",
    "print(\"Erfolgreich eingelesen!\")\n",
    "df.info()\n",
    "df.head()\n",
    "```\n",
    "\n",
    "### Excel-Dateien einlesen: `pd.read_excel()`\n",
    "\n",
    "Mit `pd.read_excel()` kann man .xlsx- und .xls-Dateien direkt einlesen, ohne Excel öffnen zu müssen. Wichtige Parameter sind sheet_name (welches Tabellenblatt?), skiprows (Überschriften oder Metadaten überspringen), usecols (nur bestimmte Spalten oder Bereiche wie „A:F“ laden) und dtype, um z. B. Kundennummern als String statt als Zahl zu erzwingen. Pandas kann Excel-Dateien sogar direkt aus einer URL laden. \n",
    "\n",
    "```python\n",
    "df_excel = pd.read_excel(\n",
    "    'mitarbeiter_demo.xlsx',\n",
    "    sheet_name='Sheet1',        # oder 0 für erstes Blatt\n",
    "    usecols='A:E',              # Excel-Spaltenbereich\n",
    "    skiprows=2,                 # z.B. Überschriften überspringen\n",
    "    dtype={'Gehalt_EUR': str}  # falls Excel komische Formate hat\n",
    ")\n",
    "```\n",
    "\n",
    "### URL einlesen: \n",
    "\n",
    "(Demnächst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ca09f3-db50-4709-a9f4-b0f23ff7b55a",
   "metadata": {},
   "source": [
    "## Selektion & Indexing in Pandas\n",
    "\n",
    "### Selektion mittels `.loc[]`, `.iloc[]` und `df[]`\n",
    "\n",
    "Die Bibliothek Pandas bietet mehrere Wege, um Zeilen und Spalten eines DataFrames auszuwählen. Je nach Situation ist eine Methode besser als die Andere.\n",
    "\n",
    "| Methode         | Was sie macht                         | Empfohlen für                     |\n",
    "|-----------------|---------------------------------------|-----------------------------------|\n",
    "| `df[]`          | Einfache Auswahl (Spalten oder bool)  | Schnell und einfach                 |\n",
    "| `.loc[]`        | Labelbasiert (Namen der Spalten/Zeilen)| Immer dann, wenn man Namen verwendet  |\n",
    "| `.iloc[]`       | Positionsbasiert (Indexnummer der Spalten/Zeilen)    | Wenn man mit Position arbeitet und es größere Dataframes sind   |\n",
    "\n",
    "\n",
    "`.loc[]` und `.iloc[]` sind sicherer als `[]`, weil sie keine Verwirrung zwischen Label und Position zulassen. Die einfachen eckigen Klammern `df[]` sind zwar praktisch, können aber zu unerwartetem Verhalten führen, wenn sich Spaltennamen und Indexwerte überschneiden. `.loc[]` und `.iloc[]` hingegen sind explizit:  \n",
    "- **`.loc[]`** arbeitet ausschließlich mit Spalten- und Zeilennamen,  \n",
    "- **`.iloc[]`** ausschließlich mit numerischen Positionen (Indexen).  \n",
    "  \n",
    "Das Wichtigste bei `.loc[]` ist, dass das Ende des Slices immer inklusiv ist.\n",
    "\n",
    "```python\n",
    "df.loc['2020-01-01':'2020-12-31']    # Hier wird der 31. Dezember 2020 mit ausgegeben\n",
    "df.loc['P2':'P5']                    # P2, P3, P4 und P5 werden angezeigt\n",
    "df.loc[10:50]                        # wenn der Index aus Zahlen besteht, so sind 10 bis 50 inklusive\n",
    "```\n",
    "\n",
    "Die `.iloc[]` Funktion ist positionsbasiert und es zählt nur die numerische Position. Wichtig zu bemerken ist, genau wie bei Listen gilt, dass das Ende des Slices exklusiv (nicht mit eingeschlossen) ist.\n",
    "\n",
    "```python\n",
    "df.iloc[0:5]     # Zeilen an Position 0, 1, 2, 3, 4. Die 5. Zeile (Index 4) ist die letzte\n",
    "df.iloc[1:4]     # Position 1, 2, 3\n",
    "df.iloc[-3:]     # die letzten drei Zeilen \n",
    "```\n",
    " \n",
    "#### Direkter Vergleich zwischen `.loc[]` und `.iloc[]`:\n",
    "\n",
    "Angenommen, unser DataFrame hat den Index `['A', 'B', 'C', 'D', 'E']`:\n",
    "\n",
    "```python\n",
    "df.loc['B':'D']   # Diese Methode liefert B, C und D (D ist inklusiv)\n",
    "df.iloc[1:4]      # liefert ebenfalls B, C, D (D ist exklusiv)\n",
    "\n",
    "df.loc['B':'E']   # liefert B, C, D und E (E ist dabei)\n",
    "df.iloc[1:5]      # liefert B, C, D und E (erst bei Position 5 wird E erreicht)\n",
    "df.iloc[1:4]      # würde nur B, C, D liefern (E fehlt)\n",
    "```\n",
    "\n",
    "### Boolsche Masken und komplexe Bedingungen\n",
    "\n",
    "Eine weitere mächtigste Funktionen von Pandas ist die Filterung mit booleschen Masken. Statt Schleifen zu schreiben, erzeugt man einen booleschen Vektor (True/False) und übergibt ihn an das DataFrame:\n",
    "\n",
    "```python\n",
    "df[df['Alter'] > 30]                                   # einfache Bedingung\n",
    "df[(df['Stadt'] == 'Berlin') & (df['Gehalt'] > 60000)] # Konjunktion\n",
    "df[(df['Abteilung'] == 'IT') | (df['Alter'] < 25)]     # Disjunktion\n",
    "```\n",
    "\n",
    "Wichtig zu bemerken ist, dass bei mehreren Bedingungen runde Klammern um jede einzelne Bedingung stehen müssen und die Operatoren `&` (und), `|` (oder) sowie `~` (nicht) werden verwendet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de94205a-0ffc-47de-9a09-76078644b787",
   "metadata": {},
   "source": [
    "## Neue Spalten erstellen & löschen\n",
    "- Einfache Berechnungen und Zuweisungen\n",
    "- apply() und lambda-Funktionen\n",
    "- map() und replace()\n",
    "- Bedingte Spalten mit np.where() und np.select()\n",
    "- drop(), pop(), del\n",
    "\n",
    "## Daten bereinigen (Cleaning)\n",
    "- Umgang mit fehlenden Werten (isnull, dropna, fillna)\n",
    "- Duplikate finden und entfernen\n",
    "- Datentypen konvertieren (astype, pd.to_datetime, pd.to_numeric)\n",
    "- String-Methoden (.str.) – lower, upper, contains, replace, split, strip\n",
    "\n",
    "## Sortieren, Ranking & Reihenfolge\n",
    "- sort_values() und sort_index()\n",
    "- rank()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51935a48-d61b-4435-a446-c210dd4d5b01",
   "metadata": {},
   "source": [
    "## Gruppieren & Aggregation\n",
    "\n",
    "Die `groupby`-Funktion ist eines der mächtigsten Werkzeuge in Pandas. Sie ermöglicht es, Daten nach einer oder mehreren Spalten zu gruppieren und dann Aggregationen (Zusammenfassungen) über diese Gruppen durchzuführen. \n",
    "Beispieldokument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aab05d0d-9a23-43fd-9dd2-1317945a6b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name  Alter  Gehalt_EUR   Eintritt  Abteilung\n",
      "0   Anna     28    52000.50 2021-03-15         IT\n",
      "1    Ben     34    68000.00 2020-11-01   Vertrieb\n",
      "2  Clara     19    45000.75 2023-07-20         IT\n",
      "3  David     42    82000.00 2019-01-10   Vertrieb\n",
      "4   Emma     31    59000.25 2022-05-05  Marketing\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = {\n",
    "    'Name': ['Anna', 'Ben', 'Clara', 'David', 'Emma'],\n",
    "    'Alter': [28, 34, 19, 42, 31],\n",
    "    'Gehalt_EUR': ['52.000,50', '68.000,00', '45.000,75', '82.000,00', '59.000,25'],\n",
    "    'Eintritt': ['2021-03-15', '2020-11-01', '2023-07-20', '2019-01-10', '2022-05-05'],\n",
    "    'Abteilung': ['IT', 'Vertrieb', 'IT', 'Vertrieb', 'Marketing']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.to_csv('mitarbeiter_demo.csv', index=False, sep=';', decimal=',')\n",
    "df = pd.read_csv(\n",
    "    'mitarbeiter_demo.csv',\n",
    "    sep=';', \n",
    "    encoding='utf-8', \n",
    "    decimal=',', \n",
    "    thousands='.', \n",
    "    parse_dates=['Eintritt'], \n",
    "    dtype={'Name': 'string', 'Abteilung': 'category'}\n",
    ")\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70acd24-da04-46c5-909e-4695947bc594",
   "metadata": {},
   "source": [
    "### Einfache Aggregationen (mean, sum, count, etc.)\n",
    "\n",
    "Mit `groupby()` kann man Daten nach einer Kategorie gruppieren und dann eine einfache Aggregationsfunktion anwenden, wie `mean()` für den Durchschnitt, `sum()` für die Summe oder `count()` für die Anzahl. Die Funktion wird auf alle numerischen Spalten angewendet, es sei denn, man spezifiziert eine Spalte. Die `groupby('Spaltenname')` Funktion teilt den DataFrame in Gruppen nach der Spalte 'Spaltenname' auf. Dann wendet `mean()` den Durchschnitt auf die angegebene Spalte an. Der Parameter `observed=True` vermeidet Warnings bei kategorischen Spalten.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4971d9c-64d9-4675-9d2e-9271c952a14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durchschnittsgehalt pro Abteilung:\n",
      "Abteilung\n",
      "IT           48500.625\n",
      "Marketing    59000.250\n",
      "Vertrieb     75000.000\n",
      "Name: Gehalt_EUR, dtype: float64\n",
      "\n",
      "Summe der Alter pro Abteilung:\n",
      "Abteilung\n",
      "IT           47\n",
      "Marketing    31\n",
      "Vertrieb     76\n",
      "Name: Alter, dtype: int64\n",
      "\n",
      "Anzahl Mitarbeiter pro Abteilung:\n",
      "Abteilung\n",
      "IT           2\n",
      "Marketing    1\n",
      "Vertrieb     2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Durchschnittsgehalt pro Abteilung\n",
    "durchschnitt_gehalt = df.groupby('Abteilung', observed=True)['Gehalt_EUR'].mean()\n",
    "print(\"Durchschnittsgehalt pro Abteilung:\")\n",
    "print(durchschnitt_gehalt)\n",
    "\n",
    "# Summe der Alter pro Abteilung\n",
    "summe_alter = df.groupby('Abteilung', observed=True)['Alter'].sum()\n",
    "print(\"\\nSumme der Alter pro Abteilung:\")\n",
    "print(summe_alter)\n",
    "\n",
    "# Anzahl Mitarbeiter pro Abteilung\n",
    "anzahl = df.groupby('Abteilung', observed=True).size()\n",
    "print(\"\\nAnzahl Mitarbeiter pro Abteilung:\")\n",
    "print(anzahl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e997ea0-36e7-460f-85be-3c79d52c9e1f",
   "metadata": {},
   "source": [
    "- Mehrere Aggregationsfunktionen gleichzeitig (agg())\n",
    "- named aggregation & as_index=False\n",
    "- Gruppierte Filterungen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8c78d2-1e2d-478b-a337-68ab472e3ac8",
   "metadata": {},
   "source": [
    "## Merges \n",
    "- concat() – Zeilen und Spalten zusammenhängen\n",
    "- merge() – inner, left, right, outer\n",
    "- join() auf Index\n",
    "- Praxisbeispiel: Kundendaten + Bestelldaten verbinden\n",
    "\n",
    "## Pivot-Tabellen\n",
    "- pivot() und pivot_table()\n",
    "- margins & margins_name\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
